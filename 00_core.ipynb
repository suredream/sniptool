{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "# default_exp core\n",
    "# default_cls_lvl 3\n",
    "# from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sniptool.core\n",
    "\n",
    "> magic commands for snippets management, supported by a sqlite db."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from IPython.core.magic import Magics, magics_class, line_magic, cell_magic\n",
    "def getmtime_ms(path):\n",
    "    mtime = os.path.getmtime(path)\n",
    "    stamp = datetime.datetime.fromtimestamp(mtime, tz=datetime.timezone.utc)\n",
    "    return int(round(stamp.timestamp()))\n",
    "\n",
    "def get_change_file(regex, last, this):\n",
    "    if not os.path.isfile(last):\n",
    "        os.system(f'touch {last}')\n",
    "    nb_list = glob(regex)\n",
    "#     print('nb_list', nb_list, regex)\n",
    "    mtime = list(map(getmtime_ms, nb_list))\n",
    "    df = (pd.DataFrame(zip(nb_list, mtime), columns=[\"path\", \"mtime\"])\n",
    "          .sort_values(by='path')\n",
    "          .to_csv(this, sep='|', index=False, header=False))\n",
    "#     print(f'diff -y --suppress-common-lines {last} {this}')\n",
    "    diff_ret = os.popen(f'diff -y --suppress-common-lines {last} {this}').read()\n",
    "    for line in diff_ret.splitlines():\n",
    "        file = line.split('|')[0].split()[-1]\n",
    "        yield file\n",
    "    os.rename(this, last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import logging\n",
    "import pycodestyle as pycodestyle_module\n",
    "import tempfile\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from io import BytesIO, StringIO\n",
    "from os.path import expanduser\n",
    "from pathlib import Path\n",
    "from pygments import highlight\n",
    "from pygments.lexers import PythonLexer\n",
    "from pygments.formatters import HtmlFormatter\n",
    "from IPython.core.display import HTML, display\n",
    "from IPython.core.magic import Magics, magics_class, line_magic, cell_magic\n",
    "from sqlalchemy import create_engine, Column, String, Float, Text\n",
    "from sqlalchemy.dialects.sqlite import insert, dialect\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "\n",
    "Base = declarative_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# define tables\n",
    "class NBfiles(Base):\n",
    "    __tablename__ = \"nbfiles\"\n",
    "    path = Column(String(256), primary_key=True)\n",
    "    mtime = Column(Float(64))\n",
    "\n",
    "\n",
    "class Snippets(Base):\n",
    "    __tablename__ = \"snippets\"\n",
    "    tags = Column(String(256))\n",
    "    desc = Column(String(256), primary_key=True)\n",
    "    source = Column(Text)\n",
    "    url = Column(String(256))\n",
    "\n",
    "\n",
    "def _snippet_parser(path):\n",
    "    sys.stdout.write(f\"updating snippets from {path}\\n\")\n",
    "    sys.stdout.flush()\n",
    "    notebook = json.load(open(path))\n",
    "\n",
    "    for cell in notebook[\"cells\"]:\n",
    "        if not cell[\"source\"]:\n",
    "            continue\n",
    "        head = cell[\"source\"][0]\n",
    "        if head.startswith(\"# @\"):\n",
    "            desc, *tags = tuple(head.lstrip(\"# @\").split(\"#\"))\n",
    "            tags = \";\".join(tags) if tags else \"\"\n",
    "            source = \"\".join(cell[\"source\"][1:])\n",
    "            url = \"\"\n",
    "            yield (\n",
    "                dict(\n",
    "                    tags=tags,\n",
    "                    desc=desc,\n",
    "                    source=source,\n",
    "                    url=url,\n",
    "                )\n",
    "            )\n",
    "\n",
    "\n",
    "def _get_file_list(targets, exclude=[\"__pycache__\", \".ipynb_checkpoints\"]):\n",
    "    \"\"\" \"\n",
    "    This function recursively prints all contents of a pathlib.Path object\n",
    "    \"\"\"\n",
    "    import configparser\n",
    "\n",
    "    nb_list = [(None, None)]\n",
    "    for target in targets:\n",
    "        target = Path(target)\n",
    "        cfg1, cfg2 = target / \"ghconfig\", target / \".git/config\"\n",
    "        if cfg1.is_file():  # has ghconfig\n",
    "            cfg = yaml.load(open(str(cfg1)), Loader=yaml.BaseLoader)\n",
    "            root = cfg[\"repo\"].rstrip(\".git\") + \"/\" + target.name\n",
    "        elif cfg2.is_file():\n",
    "            config = configparser.ConfigParser()\n",
    "            config.read(str(cfg2))\n",
    "            root = config['remote \"origin\"'][\"url\"].rstrip(\".git\") + \"/\" + target.name\n",
    "        else:\n",
    "            root = None\n",
    "        for e in exclude:\n",
    "            if target.name.find(e) != -1:\n",
    "                return list(map(list, zip(*nb_list)))\n",
    "        for file in target.iterdir():\n",
    "            if file.is_dir():\n",
    "                if \".\" in file.name:\n",
    "                    continue\n",
    "                nb_list += _get_file_list([file.absolute().as_posix()], exclude=exclude)\n",
    "            elif file.name.endswith(\".ipynb\"):\n",
    "                nb_list.append((file.absolute().as_posix(), root))\n",
    "    # remove invalid lines\n",
    "    nb_list = list(filter(lambda x: x[1], nb_list))\n",
    "    return list(map(list, zip(*nb_list)))\n",
    "\n",
    "\n",
    "# _get_file_list(['/home/jovyan/helper'], exclude=['.ipynb_checkpoints'])\n",
    "\n",
    "# def _compile_query(query):\n",
    "#     compiler = (\n",
    "#         query.compile if not hasattr(\n",
    "#             query, \"statement\") else query.statement.compile\n",
    "#     )\n",
    "#     return compiler(dialect=dialect())\n",
    "\n",
    "\n",
    "def _get_snippets_file_list(dirs):\n",
    "    include = [d for d in dirs if not d.startswith(\"!\")]\n",
    "    exclude = [d[1:] for d in dirs if d.startswith(\"!\")]\n",
    "    nb_list, links = _get_file_list(include, exclude)\n",
    "    mtime = list(map(os.path.getmtime, nb_list))\n",
    "    return pd.DataFrame(zip(nb_list, mtime, links), columns=[\"path\", \"mtime\", \"url\"])\n",
    "\n",
    "\n",
    "def _disp(snippets, short=False):\n",
    "    display(\n",
    "        HTML(\n",
    "            \"\"\"\n",
    "    <style>\n",
    "    {pygments_css}\n",
    "    </style>\n",
    "    \"\"\".format(\n",
    "                pygments_css=HtmlFormatter().get_style_defs(\".highlight\")\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    for _, row in snippets.iterrows():\n",
    "        if short:\n",
    "            content = row[\"desc\"]\n",
    "        else:\n",
    "            content = row[\"desc\"] + \"\\n\" + row[\"source\"][:80]\n",
    "        display(\n",
    "            HTML(data=highlight(f\"({_})\" + content, PythonLexer(), HtmlFormatter()))\n",
    "        )\n",
    "\n",
    "\n",
    "def _upsert(df, conn=None, model=None):\n",
    "    table = model.__table__\n",
    "    stmt = insert(table).values(df.to_dict(orient=\"records\"))\n",
    "    update_cols = [c.name for c in table.c if c not in list(table.primary_key.columns)]\n",
    "    on_conflict_stmt = stmt.on_conflict_do_update(\n",
    "        index_elements=table.primary_key.columns,\n",
    "        set_={c.key: c for c in stmt.excluded if c.key in update_cols},\n",
    "    )\n",
    "    conn.execute(on_conflict_stmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@magics_class\n",
    "class SnippetsMagics(Magics):\n",
    "    \"\"\"snip magic for snippets management.\n",
    "    Provides the %snip magic.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, shell):\n",
    "        super(SnippetsMagics, self).__init__(shell=shell)\n",
    "        dotfile = \"~/config.yaml\"\n",
    "        cfg = yaml.load(open(expanduser(dotfile)), Loader=yaml.BaseLoader)\n",
    "        self.db = cfg[\"config_dir\"] + \"/SnippetDB.db\"\n",
    "        self.search_dirs = cfg[\"search_dirs\"]\n",
    "        self.engine = create_engine(f\"sqlite:///{self.db}\")\n",
    "        Base.metadata.create_all(self.engine)\n",
    "        self.snippets = pd.read_sql(\"snippets\", self.engine)\n",
    "\n",
    "    def update(self):\n",
    "        nb_to_search = _get_snippets_file_list(self.search_dirs)\n",
    "        nb_exists = pd.read_sql(\"nbfiles\", self.engine).rename(\n",
    "            columns={\"mtime\": \"utime\"}\n",
    "        )\n",
    "        #         print(nb_to_search, nb_exists, nb_exists.empty)\n",
    "        if nb_exists.empty:\n",
    "            nb_to_update = nb_to_search.assign(isnew=True)\n",
    "        else:\n",
    "            nb_to_update = (\n",
    "                nb_exists.merge(nb_to_search, how=\"right\")\n",
    "                .fillna(0)\n",
    "                .assign(isnew=lambda x: x.mtime > x.utime + 1)\n",
    "                .query(\"isnew == True\")\n",
    "            )\n",
    "        if nb_to_update.empty:\n",
    "            print('nothing update.')\n",
    "            return\n",
    "        nestedList = nb_to_update.path.apply(_snippet_parser).to_list()\n",
    "        (\n",
    "            pd.DataFrame([item for sublist in nestedList for item in sublist])\n",
    "            .pipe(\n",
    "                _upsert, conn=self.engine, model=Snippets\n",
    "            )\n",
    "        )\n",
    "        if not nb_to_update.empty:\n",
    "            (\n",
    "                nb_to_update[[\"path\", \"mtime\"]].pipe(\n",
    "                    _upsert, conn=self.engine, model=NBfiles\n",
    "                )\n",
    "            )\n",
    "        self.snippets = pd.read_sql(\"snippets\", self.engine)\n",
    "\n",
    "    def reset(self):\n",
    "        self.engine.dispose()\n",
    "        os.remove(self.db)\n",
    "        self.engine = create_engine(f\"sqlite:///{self.db}\")\n",
    "        Base.metadata.create_all(self.engine)\n",
    "        self.update()\n",
    "\n",
    "    def info(self):\n",
    "        snippets = pd.read_sql(\"snippets\", self.engine)\n",
    "        nb_exists = pd.read_sql(\"nbfiles\", self.engine)\n",
    "        print(\n",
    "            \"{} snippets, {} notebooks in SnippetDB\".format(\n",
    "                snippets.shape[0], nb_exists.shape[0]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    @line_magic\n",
    "    def snip(self, parameter_s=\"\"):\n",
    "        \"\"\"snippets management\n",
    "\n",
    "        Usage:\n",
    "        * ``%snip``          - total numbers of all snippets and notebooks\n",
    "        * ``%snip bar``      - search in the db\n",
    "        * ``%snip -r``       - reset indexing\n",
    "        * ``%snip -u``       - update db\n",
    "        * ``%snip <key >-s``       - short output\n",
    "\n",
    "        New search directories can be inserted into config.yaml['search_dirs']\n",
    "        \"\"\"\n",
    "\n",
    "        opts, argsl = self.parse_options(parameter_s, \"rust\", mode=\"string\")\n",
    "        args = argsl.split()\n",
    "        if \"r\" in opts:\n",
    "            self.reset()\n",
    "        elif \"t\" in opts:\n",
    "            print(self.snippets)\n",
    "        elif \"u\" in opts:\n",
    "            self.update()\n",
    "        elif not args:\n",
    "            self.info()\n",
    "        elif args[-1].isdigit():  # load snippets\n",
    "            pos, q = int(args[-1]), \" \".join(args[:-1])\n",
    "            (\n",
    "                self.snippets.query(f\"desc.str.contains('{q}')\", engine=\"python\")\n",
    "                .pipe(lambda _df: _df.iloc[pos][\"source\"])\n",
    "                .pipe(self.shell.set_next_input, replace=False)\n",
    "            )\n",
    "        else:\n",
    "            q = \" \".join(args)\n",
    "            (\n",
    "                self.snippets.query(f\"desc.str.contains('{q}')\", engine=\"python\")\n",
    "                .reset_index()\n",
    "                .pipe(_disp, short=\"s\" in opts)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "@magics_class\n",
    "class MiscMagics(Magics):\n",
    "    \"\"\"snip magic for snippets management.\n",
    "    Provides the %snip magic.\n",
    "    \"\"\"\n",
    "    @line_magic\n",
    "    def d(self, parameter_s=\"\", n_cols=5, regex=\"\", cap=False):\n",
    "        import inspect\n",
    "\n",
    "        def chunks(names: list, n: int):\n",
    "            \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "            r = int(len(names) / n + 0.5)\n",
    "            for i in range(0, len(names), r):\n",
    "                yield names[i : i + r]\n",
    "\n",
    "        def output(items, n_cols=5):\n",
    "            newcolumns = list(chunks(items, n_cols))\n",
    "            n_rows, n_columns = len(newcolumns[0]), len(newcolumns)\n",
    "            newcolumns[-1].extend([\"\"] * (n_rows * n_columns - len(items)))\n",
    "            array_outputs = [[row[i] for row in newcolumns] for i in range(n_rows)]\n",
    "            col_width = (\n",
    "                max(len(word) for row in array_outputs for word in row) + 2\n",
    "            )  # padding\n",
    "            for row in array_outputs:\n",
    "                print(\"\".join(word.ljust(col_width) for word in row))\n",
    "\n",
    "        opts, argsl = self.parse_options(parameter_s, \"cn:s:\", mode=\"string\")\n",
    "        args = argsl.split()\n",
    "        if \"n\" in opts:\n",
    "            n_cols = int(opts[\"n\"])\n",
    "        if \"c\" in opts:\n",
    "            cap = True\n",
    "        if len(args) > 1:\n",
    "            regex = args[1]\n",
    "        for _, f in enumerate(inspect.stack()[4:]):\n",
    "            if args[0] in f[0].f_locals:\n",
    "                target = f[0].f_locals[args[0]]\n",
    "                items = list(filter(lambda x: x[0] != \"_\", dir(target)))\n",
    "                if regex:\n",
    "                    items = list(filter(lambda x: x.find(regex) != -1, items))\n",
    "                if not cap:\n",
    "                    items = list(filter(lambda x: x[0].islower(), items))\n",
    "                output(items, n_cols=n_cols)\n",
    "                break\n",
    "\n",
    "    @line_magic\n",
    "    def lint(self, parameter_s=\"\"):\n",
    "        opts, argsl = self.parse_options(parameter_s, \"abf\", mode=\"string\")\n",
    "        args = argsl.split()\n",
    "        assert os.path.isfile(args[0])\n",
    "        if \"f\" in opts:\n",
    "            cmd = f\"autopep8 --in-place {args[0]}\"\n",
    "            print(\"autopep8: finished\")\n",
    "        elif \"b\" in opts:\n",
    "            cmd = f\"nbblack {args[0]}\"\n",
    "        elif \"a\" in opts:\n",
    "            cmd = f\"pylint --disable=R,C --rcfile ~/.pylintrc {args[0]}\"\n",
    "        else:\n",
    "            cmd = f\"pycodestyle --show-source --ignore E501 {args[0]}\"\n",
    "        print(cmd)\n",
    "        os.system(cmd)\n",
    "\n",
    "    @cell_magic\n",
    "    def runingb(self, line, codes):\n",
    "        from multiprocessing import Process\n",
    "        from tempfile import NamedTemporaryFile\n",
    "\n",
    "        def wrapper(pyfile):\n",
    "            import subprocess\n",
    "            import time\n",
    "\n",
    "            start = time.time()\n",
    "            proc = subprocess.Popen([\"python\", pyfile], stdout=subprocess.PIPE)\n",
    "            print(proc.stdout.readline().decode())\n",
    "            print(\"Wall time:\", time.time() - start)\n",
    "\n",
    "        f = NamedTemporaryFile(mode=\"w\", suffix=\".py\", delete=False)\n",
    "        #         print(f.name)\n",
    "        with open(f.name, \"w\") as fout:\n",
    "            fout.write(codes)\n",
    "        p = Process(target=wrapper, args=(f.name,), name=\"wrapper\")\n",
    "        p.start()\n",
    "\n",
    "#     @cell_magic\n",
    "#     def toc(self, ipynb, markdown_content):\n",
    "#         def mkreader(md):\n",
    "#             for line in (\"\\n\" + md).split(\"\\n#\"):\n",
    "#                 if line:\n",
    "#                     yield (\"#\" + line)\n",
    "\n",
    "#         cells = json.load(open(ipynb))\n",
    "#         for source in reversed(list(mkreader(markdown_content))):\n",
    "#             cell = {\n",
    "#                 \"cell_type\": \"markdown\",\n",
    "#                 \"id\": \"\",\n",
    "#                 \"metadata\": {},\n",
    "#                 \"source\": [line + \"\\n\" for line in source.splitlines()],\n",
    "#             }\n",
    "#             cells[\"cells\"].insert(0, cell)\n",
    "#         with open(ipynb, \"w\") as fout:\n",
    "#             json.dump(cells, fout, indent=2)\n",
    "\n",
    "#     @line_magic\n",
    "#     def tidy(self, ipynb: str):\n",
    "#         cells = json.load(open(ipynb))\n",
    "#         cnt = 1\n",
    "#         clean_version = []\n",
    "#         for cell in cells[\"cells\"]:\n",
    "#             if cell[\"cell_type\"] == \"code\":\n",
    "#                 if not cell[\"source\"]:\n",
    "#                     continue\n",
    "#                 if not cell[\"source\"][0].startswith(\"#\"):\n",
    "#                     continue\n",
    "#                 cell[\"execution_count\"] = None\n",
    "#             elif cell[\"cell_type\"] == \"markdown\":\n",
    "#                 if not cell[\"source\"]:\n",
    "#                     continue\n",
    "#                 headline = cell[\"source\"][0]\n",
    "#                 if headline.startswith(\"#\") or headline.startswith(\"<a id=\"):\n",
    "#                     if cnt == 1:\n",
    "#                         print(\"# TOC\")\n",
    "#                     header = headline.lstrip(\"# \").strip()\n",
    "#                     print(f\"* [{header}](#cell{cnt})\")\n",
    "#                     cell[\"source\"].insert(1, f'<a id=\"cell{cnt}\"></a>\\n')\n",
    "#                     cnt += 1\n",
    "#             clean_version.append(cell)\n",
    "#         out_file = open(ipynb, \"w\")\n",
    "#         cells[\"cells\"] = clean_version\n",
    "#         json.dump(cells, out_file, indent=2)\n",
    "#         out_file.close()\n",
    "\n",
    "    @cell_magic\n",
    "    def pep8(self, line, cell, auto=False):\n",
    "        \"\"\"pycodestyle cell magic for pep8\"\"\"\n",
    "        if cell.startswith((\"!\", \"%%\", \"%\")):\n",
    "            return\n",
    "        with tempfile.NamedTemporaryFile(mode=\"r+\", delete=False) as f:\n",
    "            f.write(\"# The %%pycodestyle cell magic was here\\n\" + cell)\n",
    "            f.flush()\n",
    "            f.close()\n",
    "        format = \"%(row)d:%(col)d: %(code)s %(text)s\"\n",
    "        pycodestyle = pycodestyle_module.StyleGuide(format=format)\n",
    "        pcs_result = pycodestyle.check_files(paths=[f.name])\n",
    "        try:\n",
    "            os.remove(f.name)\n",
    "        except OSError as e:  # if failed, report it back to the user ##\n",
    "            logger.error(\"Error: %s - %s.\" % (e.filename, e.strerror))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @check package version #rt\n",
    "!pip list | egrep 'pandas|matplotlib|numpy|seaborn|xarray|rasterio' | sed -e 's/ \\+/==/g'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sniptool"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
